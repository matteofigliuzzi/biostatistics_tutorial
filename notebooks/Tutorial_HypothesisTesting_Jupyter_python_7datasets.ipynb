{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the biostatistics tutorial!\n",
    "\n",
    "In this tutorial we will use Python language to analyze some biological datasets and perform statistical analysis and statistical tests. The tutorial was created in Jupyter notebook and can be run as a live notebook, either in the cloud, or you can download it and run it locally in you computer.\n",
    "\n",
    "**Important:** You don't have to know how to code in Python to execute the notebook! \n",
    "\n",
    "Just focus on concepts and basic ideas behind the statistical analysis, not on the code (you only have to follow the instructions to execute the cells as you scroll through the notebook).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of the Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze 7 data sets using different statistical tests:\n",
    "\n",
    "1. Fisher Exact test for association between mutant genotype and a binary phenotype\n",
    "2. Welch's t-test for unequal variances for association between mutant genotype and a continuous phenotype\n",
    "3. Logistic regression to assess the impact of SCD on ovarian reserve\n",
    "4. Student's t-test on log transformed responses\n",
    "5. Logistic regression for categorical response and two treatment variables\n",
    "6. Chi-Square contingency test on combined response and combined treatment groups\n",
    "7. ANOVA with Tukey-Kramer post-hoc\n",
    "\n",
    "For each example, the following steps are taken:\n",
    "\n",
    "-  State biological hypothesis\n",
    "-  State the number and types of variables\n",
    "-  Determine the preferred statistical test and null hypothesis\n",
    "-  Check if data meet the assumptions of the preferred statistical test\n",
    "-  Decide what statistical test to use\n",
    "-  Run the statistical test\n",
    "-  Interpret the results of the statistical test\n",
    "-  Display the data and statistical results in a figure\n",
    "\n",
    "You do not need to install Python or perform any of the analyses in the tutorial in order to learn from the examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source of datasets\n",
    "\n",
    "- Dataset 1 contains random data generated specifically for this tutorial;\n",
    "- Datasets 2,4,5,6,7 are taken from: Pollard et al (2019), \"Empowering Statistical Methods for Cellular and Molecular Biologists\",  MBOC Vol. 30, No. 12 https://www.molbiolcell.org/doi/full/10.1091/mbc.E15-02-0076 \n",
    "- Dataset 3 (ovarian reserve data) is derived from: Kopeika et al. (2019), \"Ovarian reserve in women with sickle cell\n",
    "disease\", Plos ONE https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0213024&type=printable\n",
    "\n",
    "If you wish you can download the datasets (provided as Excel files) from here:\n",
    "https://github.com/matteofigliuzzi/biostatistics_tutorial/tree/main/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The computational tools\n",
    "\n",
    "## What is Python?\n",
    "\n",
    "Python is a high-level, interpreted, general-purpose programming language. It provides a wide range of tools useful to perform biostatistical analysis. You can find a simple tutorial focusing on the essentials you need to know to start programming with Python.\n",
    "https://realpython.com/python-first-steps/\n",
    "\n",
    "## What is a Jupyter notebook?\n",
    "\n",
    "A Jupyter Notebook is an open source application that you can use to create and share documents that contain live code in different languages (such as Python or R), analysis, visualizations, and text. \n",
    "\n",
    "In a Jupyter notebook code blocks are in grey boxes (see just below), and output from running the code (including text, results of calculations and plots) just after the python code blocks.\n",
    "\n",
    "To execute the code, click on the cell, and then use the \"Run\" button in the top menu ($\\blacktriangleright$) or alternatively press shift + enter (press enter while keeping pressed shift). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('this is the output from some python code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These first 2 lines are a comment in Python, as they starts with the pound sign \"#\"\n",
    "# print('this is just a comment, it is not run')\n",
    "\n",
    "print(3+5) # in this line the comment starts after the print command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create new blocks or, alternatively, you can edit the code of existing blocks:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to edit the content below to change the output of the cell\n",
    "\n",
    "a=22\n",
    "b=5\n",
    "print(a+b)\n",
    "\n",
    "c='questa Ã¨ una stringa'\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the output, you have to execute the code again, clicking on the cell and then using the \"Run\" button in the top menu ($\\blacktriangleright$) or pressing shift + enter. \n",
    "\n",
    "If you run the following cell you will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5\n",
    "y = 2\n",
    "\n",
    "##option A\n",
    "# z = x+y\n",
    "\n",
    "##option B\n",
    "# z = x-y\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What happened? Why we got an error?\n",
    "\n",
    "In previous cell, try to uncomment (remove the '#' symbol) the line below one of the two options, and execute again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested, you can find more information on Jupyter notebooks here: https://realpython.com/jupyter-notebook-introduction/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run this Jupyter notebook on cloud?\n",
    "\n",
    "You don't have to do anything but copy and paste the following URL in your web browser:\n",
    "\n",
    "https://mybinder.org/v2/gh/matteofigliuzzi/biostatistics_tutorial/main?labpath=notebooks%2FTutorial_HypothesisTesting_Jupyter_python.ipynb\n",
    "\n",
    "and an interactive notebook session will be opened in your browser.\n",
    "\n",
    "In case you are curious how it works: I have pre-built a Binder repository associated to the following github repo: https://github.com/matteofigliuzzi/biostatistics_tutorial . Binder is a service provided by the Binder Project. It allows you to input the URL of any public Git repository, and it will open that repository within the native Jupyter Notebook interface. You can run any notebooks in the repository, though any changes you make will not be saved back to the repository. The repository must include a configuration file that specifies its package requirements, which are used by Binder to build a Docker image, in which all configurations and dependencies to run the notebook are satisfied.\n",
    "\n",
    "## How to run this notebook locally on you computer?\n",
    "\n",
    "To run the notebook on your computer, you have to download it from here: https://github.com/matteofigliuzzi/biostatistics_tutorial and make sure that you have Python and Jupyter notebook installed (and all dependencies satisfied).\n",
    "\n",
    "### Installing python\n",
    "Installing Python is generally easy, and nowadays most Linux and UNIX distributions include a recent Python. Even some Windows computers now come with Python already installed. If you do need to install Python, follow the incrusctions on this page: https://wiki.python.org/moin/BeginnersGuide/Download\n",
    "\n",
    "\n",
    "### Downloading and using Jupyter\n",
    "To install Jupyter in your computer follow the instructions on this page: https://jupyter.org/install\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries\n",
    "\n",
    "In Python language, libraries, packages and modules are files (or group of files) containing specialized functions.\n",
    "\n",
    "Although you only have to install a specialized library once (this was done by Binder if you are running the notebook on cloud), you have to load it every time you restart python and want to use functions in the library.  \n",
    "\n",
    "Libraries, packages or modules can be loaded using the import statement as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fundamental packages for scientific computing with Python\n",
    "import numpy as np \n",
    "from scipy import stats as st\n",
    "\n",
    "#Package for data analysis and manipulation tool\n",
    "import pandas as pd \n",
    "\n",
    "#Packages for data visualization \n",
    "import seaborn as sns \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Package for biostatistical analysis, check documentation here https://github.com/reneshbedre/bioinfokit\n",
    "from bioinfokit.analys import stat \n",
    "\n",
    "print('library imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Test for association between mutant genotype and a binary phenotype\n",
    "\n",
    "In this first example, we are testing the biological hypothesis that a mutant genotype affects a phenotype we are measuring. Our statistical null hypothesis is that genotype has no effect on the phenotype.\n",
    "\n",
    "There are two variables in the experiment: Genotype and Phenotype. \n",
    "\n",
    "- Genotype (our independent variable) is a categorical variable with two possible values: WT and Mutant. \n",
    "- Phenotype (our dependent variable) is a categorical binary variable: Pizza or Pasta.\n",
    "\n",
    "We will run a statistical test to check if they are significantly associated or not.\n",
    "\n",
    "**Question**: Which Statistical Test would you perform? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read fist data file into dataframe (using pandas library)\n",
    "data0 = pd.read_excel('../data/dataset0.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first 5 lines of the dataframe\n",
    "data0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the last 3 lines of the dataframe\n",
    "data0.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code blocks we read the data in from an Excel file and saved it in a data frame variable called 'data1'. The data appears to have been read in correctly. Each row is a record and the columns are the variables. In this case, each individual has a genotype and measurement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the size of the dataframe (rows, columns)\n",
    "data0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas to calculate phenotype frequency\n",
    "data0['Phenotype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas to calculate genotype frequency\n",
    "data0['Genotype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pandas to calculate a contingency table\n",
    "table = pd.crosstab(data0.Phenotype,data0.Genotype)\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram of the phenotype data, stratified by genotype\n",
    "sns.histplot(data=data0,x='Genotype',hue='Phenotype',multiple='dodge',shrink=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with binary categorical variables, we will perform a fisher exact test to test their association.\n",
    "We will set the significancy level alpha=0.05.\n",
    "\n",
    "**Quesiton:** what is the null hypothesis for the fisher exact test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Fisher exact test,\n",
    "oddsratio,pvalue = st.fisher_exact(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Odds ratio is:',oddsratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fisher Exact Test p-value is:',pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: given the significancy was set at 0.05, are we accepting or rejecting the null hypothesis?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Test for association between mutant genotype and a continuous phenotype\n",
    "\n",
    "In this example, we are testing again the biological hypothesis that a mutant genotype affects a phenotype we are measuring. Again, our statistical null hypothesis is that genotype has no effect on the measurement.\n",
    "\n",
    "Genotype is again a categorical variable with two possible values: WT and Mutant, but \n",
    "Measurement is now a continuous numerical variable. \n",
    "\n",
    "**Question:** Which test would you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read fist data file into data frame object\n",
    "data1 = pd.read_excel('../data/dataset1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first several rows of data\n",
    "data1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the size of the dataframe (rows, columns)\n",
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at summary information on the Measurement variable\n",
    "data1['Measurement'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The describe function shows us some information about the data. For example we learn that the measurements range from 2 to 45.\n",
    "\n",
    "Based on these two variables, we will run a Student's two-sample t-test as long as we can meet the assumptions of that test: \n",
    "- normally distributed responses within each treatment  \n",
    "- equal variances between treatments\n",
    "\n",
    "We have to look at our data to see if we have met these assumptions, so we will plot the data \n",
    "and calculate  summary statistics.\n",
    "\n",
    "**Question:** which plotting method would you choose? Uncomment the options below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment one of the following plotting options\n",
    "\n",
    "plotting = 'undefined'\n",
    "\n",
    "#plotting = 'boxplot' \n",
    "#plotting = 'swarmplot'\n",
    "#plotting = 'violin-plot'\n",
    "\n",
    "print(plotting)\n",
    "\n",
    "if plotting == 'boxplot':\n",
    "    # plot data as boxplot\n",
    "    sns.boxplot(data=data1,x='Genotype',y='Measurement')\n",
    "elif plotting == 'swarmplot':\n",
    "    # plot data as swarmplot\n",
    "    sns.swarmplot(data=data1,x='Genotype',y='Measurement')\n",
    "elif plotting == 'violin-plot':\n",
    "    # plot data as violin-plot\n",
    "    sns.violinplot(data=data1,x='Genotype',y='Measurement')\n",
    "else:\n",
    "    print('I don\\'t know this option!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now plot the histogram of phenotype data, stratified by genotype.\n",
    "\n",
    "Try to change the value of variable number_of_bins to modify the binning.\n",
    "\n",
    "**Question:** how many bins would you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data as stacked histograms\n",
    "\n",
    "#binning\n",
    "number_of_bins = 3 #\n",
    "\n",
    "\n",
    "min_value = np.floor(data1['Measurement'].min())\n",
    "max_value = np.ceil(data1['Measurement'].max())\n",
    "bins = np.linspace(min_value,max_value,number_of_bins+1)\n",
    "\n",
    "fig,ax=plt.subplots(2,1,sharex=True)\n",
    "ax[0].set_title('Mutant')\n",
    "sns.histplot(data=data1[data1.Genotype=='Mutant'],x='Measurement',ax=ax[0],bins=bins)\n",
    "ax[1].set_title('WT')\n",
    "sns.histplot(data=data1[data1.Genotype=='WT'],x='Measurement',ax=ax[1],bins=bins)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary statistics, stratified by genotype\n",
    "data1.groupby('Genotype').agg(['count','mean','median','std','var'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the boxplot/violinplot/swarmplot we can tell that the variances are somewhat different between genotypes. The histplot function makes histograms. The stacked histograms give a sense for the shapes of each distribution. Although neither looks perfectly normal, neither is strongly skewed. \n",
    "\n",
    "The groupby method helps us organize our summary statistics for each genotype. \n",
    "\n",
    "The median and mean values for each genotype are very similar, confirming that the distributions are not highly skewed. From this information, we will say that the data have met the t-test assumption of normally distributed responses in each treatment. What about equal variances between treatments? The variances are an order of magnitude different, which violates the assumption of the t-test.\n",
    "\n",
    "Instead of a Student's t-test, we can run a Welch's t-test which assumes normality but does not assume equal variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know more about how to use a function use help():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can use scipy library to calculate T test\n",
    "\n",
    "#extract measurement data from WT records\n",
    "data_wt = data1[data1.Genotype=='WT']['Measurement'].values\n",
    "\n",
    "#extract measurement data from mutant records\n",
    "data_mutant = data1[data1.Genotype=='Mutant']['Measurement'].values\n",
    "\n",
    "# run Welch's t-test on data, setting alpha=0.05\n",
    "test_result = st.ttest_ind(data_wt,data_mutant,equal_var=False,alternative='two-sided')\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our p-value is less than our alpha value of 0.05 so we reject the null hypothesis that genotype has no effect on our measured response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, if you are more familiar with R output, we can use the bioinfokit library to calculate Welch's t-test on data \n",
    "res = stat()\n",
    "res.ttest(df=data1,xfac='Genotype',res='Measurement',evar=False,test_type=2)\n",
    "print(res.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(res.ttest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reporting this result in a paper it is best to include t, df, and p-value. Here is what that might look like:\n",
    "\n",
    "The mutant had significantly different measurements than wild type (Welch's t(2,0.05) = -3.57, df = 27.9, p-value < 0.0015).\n",
    "\n",
    "The numbers in parentheses next to the t are 2 for a two-sided test (i.e. allowing the effect of the mutant to both increase or decrease the measurement) and 0.05 for the alpha value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Logistic regression to predict Ovarian Reserve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we analyze real data from: Kopeika et al. (2019), Ovarian reserve in women with sickle cell disease, Plos ONE\n",
    "\n",
    "In this study the authors investigate if women of reproductive age with sickle cell disease (SCD, Anemia Flaciforme)  are more likely to\n",
    "have a low ovarian reserve (AMH<5) at a younger age in comparison with patients with no\n",
    "haemoglobinopathy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('../data/dataset_amh.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the first rows of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['AMH<5'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dependent variable (AMH<5) and three independent variables (SCD, Smoking Status & Age).\n",
    "\n",
    "The biological hypothesis is that SCD affects AMH levels. We include Age and Smoking status as so called covariates, or 'nuisance' treatment variable. Our statistical null hypotheses is that the frequency of Low AMH is the same independently of the SCD.\n",
    "\n",
    "Since our response variable is a binary categorical variable, a possible type of regression is the **logistic** regression. The logistic regression model will predict the probability of low AMH depending on SCD, the age and the smoking status. We can also test the hypotheses using logistic regression and a series of Wald tests. \n",
    "\n",
    "This approach makes few assumptions about the structure of the data and the function that we will use will warn us if our data are not meeting those assumptions.\n",
    "\n",
    "More information on performing logistic regression in python can be found here:\n",
    "- https://realpython.com/logistic-regression-python/\n",
    "- https://www.reneshbedre.com/blog/logistic-regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('SCD')[['Age','Smoking','AMH']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot AMH data as boxplot\n",
    "sns.boxplot(data=data,x='SCD',y='AMH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Age data as boxplot\n",
    "sns.boxplot(data=data,x='SCD',y='Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binning\n",
    "num_bins= 15\n",
    "min_value = data['AMH'].min()\n",
    "max_value = data['AMH'].max()\n",
    "\n",
    "bins = np.linspace(min_value,max_value,num_bins+1)\n",
    "\n",
    "# plot data as stacked histograms\n",
    "fig,ax=plt.subplots(2,1,sharex=True)\n",
    "ax[0].set_title('SCD')\n",
    "sns.histplot(data=data[data.SCD==1],x='AMH',ax=ax[0],bins=bins)\n",
    "ax[1].set_title('not SCD')\n",
    "sns.histplot(data=data[data.SCD==0],x='AMH',ax=ax[1],bins=bins)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('SCD')[['AMH']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Welch's t-test on data, setting alpha=0.05\n",
    "st.ttest_ind(data[data.SCD==0]['AMH'],data[data.SCD==1]['AMH'],equal_var=False,alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering:\n",
    "\n",
    "# age class\n",
    "def age_class(x):\n",
    "    if x<=30:\n",
    "        return '<30'\n",
    "    elif x<=35:\n",
    "        return '31-35'\n",
    "    elif x<=40:\n",
    "        return '36-40'\n",
    "    else:\n",
    "        return '>41'\n",
    "data['Age class'] = data['Age'].apply(age_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amh_by_ageclass = data.groupby(['Age class','SCD'])['AMH<5'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=amh_by_ageclass,x='Age class',hue='SCD',y='AMH<5',order=['<30','31-35','36-40','>41'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a few more modules to perform logistic regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import statsmodels.api as sm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model\n",
    "# get independent variables\n",
    "data['Constant'] = 1\n",
    "X = data[['Age','SCD','Smoking','Constant']]\n",
    "# to get intercept -- this is optional\n",
    "# X = sm.add_constant(X)\n",
    "# get response variables\n",
    "Y = data[['AMH<5']]\n",
    "# fit the model with maximum likelihood function\n",
    "model = sm.Logit(endog=Y, exog=X).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section of the function output that we are most interested in is the coefficients. The line that starts with \"SCD\" tells us about the effect of SCD. The magnitude of the effect of being affected by SCD is 0.99. This coefficient is calculated as the natural log of the odds ratio. A Wald test was run on this coefficient to determine if it is a significant departure from what would be expected if there was no effect of genotype. The Wald test is based on z-scores. Dividing the coefficient by the standard error results in a z-score of 2.26 which has a p-value < 0.025. So SCD has a significant effect on the probability of low AMH.\n",
    "\n",
    "There were significant effects also for the Age (p<1e-3). By including it as a variable in the model we were able to estimate and therefore control for significant variation in the AMH across different age. Controling for the age effect allowed us to more accurately estimate the effect and significance of genotype.\n",
    "\n",
    "No significant effect is detected for smoking status (p=0.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odds Ratio = (Low AMH SCD / High AMH SCD) / (Low AMH notSCD / High AMH notSCD)\n",
    "np.exp(model.params['SCD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Student's t-test on log transformed responses\n",
    "In this second example we are working with a very similar dataset as example 2. The dataset has the same types of variables and we are interested in the same biological hypothesis. The difference comes when we inspect the data to see if it meets the assumptions of a Student's t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read second data file into data frame object\n",
    "data2 = pd.read_excel('../data/dataset2.xlsx')\n",
    "# look at the first several rows of data\n",
    "data2.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at summary information\n",
    "data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data as boxplot\n",
    "sns.boxplot(data=data2,x='Genotype',y='Measurement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binning\n",
    "num_bins= 15\n",
    "min_value = data2['Measurement'].min()\n",
    "max_value = data2['Measurement'].max()\n",
    "\n",
    "bins = np.linspace(min_value,max_value,num_bins+1)\n",
    "\n",
    "# plot data as stacked histograms\n",
    "fig,ax=plt.subplots(2,1,sharex=True)\n",
    "ax[0].set_title('Mutant')\n",
    "sns.histplot(data=data2[data2.Genotype=='Mutant'],x='Measurement',ax=ax[0],bins=bins)\n",
    "ax[1].set_title('WT')\n",
    "sns.histplot(data=data2[data2.Genotype=='WT'],x='Measurement',ax=ax[1],bins=bins)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary statistics, stratified by genotype\n",
    "data2.groupby('Genotype').agg(['count','mean','median','std','var'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regard to normality, the measurement responses appear to be somewhat skewed to the right. The median values are less than the mean values, consistent with a slight skew. This might be a violation of the assumption of normality. The responses for the mutant also appear to be slightly bimodal. Student's t-test is robust to small deviations from normality so it is unclear if these departures from normality will be a problem.\n",
    "\n",
    "The variances are just about three-fold different. Student's t-test is robust to this level of difference in variance but only when the design is balanced. The sample sizes are somewhat different so again we are close to violating this assumption.\n",
    "\n",
    "The skew in the response is the more serious violation because if it cannot be corrected then we will need to use a non-parametric test with lower power. Right-skewed distributions can sometimes be corrected using a natural log. Note that the function np.log() in python defaults to the natural log, which is commonly written as ln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ln transformation\n",
    "data2['LnMeasurement'] = np.log(data2['Measurement'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binning\n",
    "min_value = data2['LnMeasurement'].min()\n",
    "max_value = data2['LnMeasurement'].max()\n",
    "bins = np.linspace(min_value,max_value,num_bins+1)\n",
    "\n",
    "# plot data as stacked histograms\n",
    "fig,ax=plt.subplots(2,1,sharex=True)\n",
    "ax[0].set_title('Mutant')\n",
    "sns.histplot(data=data2[data2.Genotype=='Mutant'],x='LnMeasurement',ax=ax[0],bins=bins)\n",
    "ax[1].set_title('WT')\n",
    "sns.histplot(data=data2[data2.Genotype=='WT'],x='LnMeasurement',ax=ax[1],bins=bins)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary statistics, stratified by genotype\n",
    "data2.groupby('Genotype')['LnMeasurement'].agg(['count','mean','median','std','var'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformation improved the shape of the distributions to be more normal in appearance. The natural log transformation also resulted in the variances being very similar between genotypes. The dataset with natural log transformations of the measurement responses meet the assumptions of Student's t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run t-test on ln transformed data with alpha set to 0.05 and assumption of equal variance\n",
    "data_wt = data2[data2.Genotype=='WT']['LnMeasurement']\n",
    "data_mutant = data2[data2.Genotype=='Mutant']['LnMeasurement']\n",
    "\n",
    "\n",
    "test_result = st.ttest_ind(data_wt,data_mutant,equal_var=False,alternative='two-sided')\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run t-test on ln transformed data with alpha set to 0.05 and assumption of equal variance\n",
    "data_wt = data2[data2.Genotype=='WT']['Measurement']\n",
    "data_mutant = data2[data2.Genotype=='Mutant']['Measurement']\n",
    "\n",
    "\n",
    "test_result = st.ttest_ind(data_wt,data_mutant,equal_var=False,alternative='two-sided')\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mutant had significantly different measurements than wild type (Student's t(2,0.05) = -12.299, df = 61, p-value < 2.2e-16).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5: Logistic regression for categorical response and two treatment variables\n",
    "In the first examples we had a continuous numerical response variable and a single categorical treatment variable. In this example we have a categorical response variable (Phenotype) and two categorical treatment variables (Genotype & Day).\n",
    "\n",
    "Our biological hypothesis is that genotype (disomic vs trisomic) affects the proportion of cells that are ciliated. Data was collected over many days so we include Day as a so called covariates, or 'nuisance' treatment variable. Our statistical null hypotheses are that the proportion of ciliated cells is the same across genotypes and that the proportion of ciliated cells is the same across days.\n",
    "\n",
    "Since our response variable is a binary categorical variable, a possible type of regression is the **logistic** regression. The logistic regression model will predict the probability of being ciliated depending on genotype and day. We can also test the hypotheses using logistic regression and a series of Wald tests. \n",
    "\n",
    "\n",
    "This approach makes few assumptions about the structure of the data and the function that we will use will warn us if our data are not meeting those assumptions.\n",
    "\n",
    "More information on performing logistic regression in python can be found here:\n",
    "- https://realpython.com/logistic-regression-python/\n",
    "- https://www.reneshbedre.com/blog/logistic-regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a few more modules to perform logistic regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import statsmodels.api as sm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read third data file into data frame object\n",
    "# from Domenico Galati et al 2018, Fig 1 (https://doi.org/10.1016/j.devcel.2018.07.008)\n",
    "data3 = pd.read_excel('../data/dataset3.xlsx')\n",
    "\n",
    "#show first lines\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now run the logistic regression function on the data. We need to tell the function function which variable is the response variable and which variables are treatment variables. \n",
    "\n",
    "Before that, we have to encode the categorical varibles as binary numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical variables in binary numeric variables\n",
    "data3['Genotype_numeric'] = data3['Genotype'].replace(['Disomic','Trisomic'],[0,1])\n",
    "data3['Phenotype_numeric'] = data3['Phenotype'].replace(['Ciliated','Not Ciliated'],[0,1])\n",
    "data3['Constant']=1 #add constant observation to fit intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sm.Logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model\n",
    "# get independent variables\n",
    "X = data3[['Day','Genotype_numeric','Constant']]\n",
    "# to get intercept -- this is optional\n",
    "# X = sm.add_constant(X)\n",
    "# get response variables\n",
    "Y = data3[['Phenotype_numeric']]\n",
    "# fit the model with maximum likelihood function\n",
    "model = sm.Logit(endog=Y, exog=X).fit(maxiter=1000,tol=1e-9)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section of the function output that we are most interested in is the coefficients. The line that starts with \"GenotypeTrisomic\" tells us about the effect of genotype. The magnitude of the effect of being Trisomic vs Disomic is 1.2918. This coefficient is calculated as the natural log of the odds ratio. A Wald test was run on this coefficient to determine if it is a significant departure from what would be expected if there was no effect of genotype. The Wald test is based on z-scores. Dividing the coefficient by the standard error results in a z-score of 5.29 which has a p-value < 1e-10. So genotype has a very significant effect on the proportion of cells with cilia.\n",
    "\n",
    "Simiarly, there were significant effects of what day the experiment was conducted on. Although the effect of day was not of interest, by including it as a variable in the model we were able to estimate and therefore control for significant variation in the proportion of cells with cilia across days. Controling for the day effect allowed us to more accurately estimate the effect and significance of genotype.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odds Ratio = (Ciliated Disomic / Not Ciliated Disomic) / (Ciliated Trisomic / Not Ciliated Trisomic)\n",
    "np.exp(model.params['Genotype_numeric'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use the the sklearn linear model module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a generalized linear model of Phenotype with binomial errors and Genotype and Day as treatments\n",
    "model = linear_model.LogisticRegression(tol=0.00000001,max_iter=1000,penalty='none',fit_intercept=False)\n",
    "\n",
    "x = data3[['Day','Genotype_numeric','Constant']]\n",
    "y = data3['Phenotype_numeric']\n",
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coeff\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.score(x,y)\n",
    "#confusion_matrix(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odds Ratio = (Ciliated Disomic / Not Ciliated Disomic) / (Ciliated Trisomic / Not Ciliated Trisomic)\n",
    "np.exp(model.coef_[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 6: Chi-Square contingency test on combined response and combined treatment groups\n",
    "This example is similar to the previous example in that there is a categorical response variable and the treatment is categorical. However, in this example there is only one categorical treatment variable so instead of logistic regression we can run a chi-square contingency test.\n",
    "\n",
    "The biological hypothesis is that loss of expression of the gene JMJD2A causes decreased expression of the gene Sox2 in developing chicken neural plate. The four treatments were control morpholino (Control-MO), translation blocking JMJD2A morpholino (JmjD2A-tbMO), splicing blocking JMJD2A morpholino (JmjD2A-sbMO), and splicing blocking JMJD2A morpholino plus JmjD2A full-length rescue vector. The response was Sox2 expression for each embryo categorized as full wild type expression (WT), mild decrease in expression (Mild), or strong decrease in expression (Strong). An appropriate null hypothesis is that Sox2 expression response is independent of JMJD2A treatment.\n",
    "\n",
    "We can test our null hypothesis with a chi-square contingency test. The test calculates the expected counts of each combination of treatment and response assuming independence. The assumptions of the test are that none of the expected counts are less than 1 and <20% of the expected counts are less than 5. Let's look at the data to see if they meet these assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read fourth data file into data frame object\n",
    "data4 = pd.read_excel('../data/dataset4.xlsx')\n",
    "data4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a contingency table\n",
    "table = pd.crosstab(data4.Treatment,data4.Phenotype)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crosstab function calculated a contingency table, a table of counts for combinations of treatment and phenotype (Sox2 expression). An efficient way to get the expected counts from the observed counts is to run the st.chi2_contingency function and then print out the expected counts which it calculates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run chi-square test with correct = F because this is not a 2x2 table\n",
    "chi2test = st.chi2_contingency(table,correction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print expected counts\n",
    "chi2test[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the expected counts meet the first assumption that none can be less than 1, they do not meet the second assumption that <20% are less than 5. 5 out of 12 (41.7%) are less than 5.\n",
    "\n",
    "There are two ways to handle this situation. One way is to increase sample sizes for each of the treatments. Another way is to consider if any of the treatment or response categories could be combined such that the assumption is satisfied while keeping the outcome of the hypothesis test interpretable and meaningful.\n",
    "\n",
    "Given the biological hypothesis that loss of expression of the gene JMJD2A causes decreased expression of the gene Sox2, the two treatments intended to decrease expression of JMJD2A (JmjD2A-tbMO & JmjD2A-sbMO) could be combined and the two responses that involve decreased expression of Sox2 (Mild & Strong) could be combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a contingency table\n",
    "data4['Phenotype_comb'] = data4['Phenotype'].replace({'Mild':'MildStrong','Strong':'MildStrong'})\n",
    "data4['Treatment_comb'] = data4['Treatment'].replace({'JmjD2A-sbMO':'JmjD2A-sbMOtbMO','JmjD2A-tbMO':'JmjD2A-sbMOtbMO'})\n",
    "table_comb = pd.crosstab(data4.Treatment_comb,data4.Phenotype_comb)\n",
    "table_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the expected counts for this new observed counts table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run chi-square test with correct = F because this is not a 2x2 table\n",
    "chi2test_comb = st.chi2_contingency(table_comb,correction=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all expected values are 5 or more so the assumptions of the test have been met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print expected counts\n",
    "chi2test_comb[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pvalue\n",
    "chi2test_comb[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test resulted in a significant p-value. So we reject the null hypothesis that Sox2 expression is independent of treatments decreasing JMJD2A expression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 7: ANOVA with Tukey-Kramer Post-hoc\n",
    "In this example there is a categorical treatment variable and a continuous numerical response variable, just like the first two examples. However, in this example, the categorical treatment variable has four groups, three RNAi treatments and one control treatment.\n",
    "\n",
    "The biological hypothesis is that RNAi against all three members of the ZLW gene family results in decreased fluorescence intensity of a reporter. A common mistake is to perform a series of t-tests, which does not control the false positive rate at or below 0.05. If all six pairwise comparisons were made using t-tests, the false positive rate would be capped at 6 x 0.05 = 0.3, which is quite high. A single ANOVA test can be run to determine if any of the mean responses across treatments are different. The null hypothesis is that the mean responses are the same across all treatments. If we reject this null hypothesis from the ANOVA, we can then run a Tukey-Kramer post-hoc analysis to determine which pairs of treatments are significantly different. And all of that can be done while keeping the false positive rate no higher than 0.05.\n",
    "\n",
    "ANOVA has the same assumptions as t-tests: normality of responses within treatments and equal variances across treatments. Let's see if the data meet these assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read fifth data file into data frame object\n",
    "data5 = pd.read_excel('../data/dataset5.xlsx')\n",
    "\n",
    "data5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5.Treatment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=data5,x='Treatment',y='Intensity',color='lightblue')\n",
    "sns.swarmplot(data=data5,x='Treatment',y='Intensity',color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binning\n",
    "min_value = data5['Intensity'].min()\n",
    "max_value = data5['Intensity'].max()\n",
    "print(min_value,max_value)\n",
    "\n",
    "bins = np.linspace(min_value,max_value,15)\n",
    "print(bins)\n",
    "\n",
    "# plot data as stacked histograms\n",
    "fig,ax=plt.subplots(4,1,sharex=True,figsize=(8,10))\n",
    "i=0\n",
    "for treatment in data5['Treatment'].unique():\n",
    "    ax[i].set_title(treatment)\n",
    "    sns.histplot(data=data5[data5.Treatment==treatment],x='Intensity',ax=ax[i],bins=bins)\n",
    "    i = i+1\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary statistics, stratified by genotype\n",
    "data5.groupby('Treatment')['Intensity'].agg(['count','mean','median','std','var'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions of responses for each treatment look approximately normally distributed. The variances are not equal but are all less than three fold different. ANOVA is robust to this level of difference in variance as long as the experiment is balanced. Sample sizes are large and almost identical so it is balanced. It appears we have met the assumptions of ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_control = data5[data5.Treatment == 'control']['Intensity']\n",
    "data_zlw1 = data5[data5.Treatment == 'ZLW1-RNAi']['Intensity']\n",
    "data_zlw2 = data5[data5.Treatment == 'ZLW2-RNAi']['Intensity']\n",
    "data_zlw3 = data5[data5.Treatment == 'ZLW3-RNAi']['Intensity']\n",
    "\n",
    "#ANOVA\n",
    "st.f_oneway(data_control,data_zlw1,data_zlw2,data_zlw3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f_oneway function, runs what is called an F-test. Large values of F mean that the differences in responses amongst treatments are large compared to differences in responses within treatments. F values close to 1 mean that the differences in responses amongst treatments are similar to differences in responses within treatments. In our case, we got an F value of 28.68, which is very large and has a very significant p-value of 2.7e-16. We therefore reject the null hypothesis that the mean responses are the same across treatments.\n",
    "\n",
    "If and only if you get a significant result from an ANOVA, you can run a Tukey-Kramer post-hoc analysis to determine which pairs of treatments differ significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# perform multiple pairwise comparison (Tukey's HSD)\n",
    "# unequal sample size data, tukey_hsd uses Tukey-Kramer test\n",
    "res = stat()\n",
    "res.tukey_hsd(df=data5, res_var='Intensity', xfac_var='Treatment', anova_model='Intensity ~ C(Treatment)')\n",
    "res.tukey_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TukeyHSD() function performed the post-hoc analysis. The function returns a table with each of the six pairwise comparisons of treatments as the rows. The columns are 'diff', which is the difference in mean responses between the two treatments, 'lwr' and 'upr', which are the bounds of the 95% confidence interval for the 'diff', and 'p adj', which is the p-value from a q-test. In this case, five of the six possible pairwise comparisons had significantly different responses, demonstrated by a 'p adj' value less than 0.05 and a confidence interval that does not overlap zero. Only ZLW3 RNAi vs ZLW1 RNAi was not significant.\n",
    "\n",
    "By using the ANOVA to Tukey-Kramer approach, we have kept the false positive rate at or below 0.05. We can draw the conclusion that RNAi of all three ZLW family genes significantly decreases fluorescence intensity of our reporter relative to a control. We can further say that RNAi of ZLW2 has a stronger effect on the fluorescence intensity of the reporter than ZLW1 and ZLW3.\n",
    "\n",
    "For displaying our results in a figure, we can use a stripchart with mean and 95% confidence intervals overlayed like we did for examples 1 and 2. We have already calculated the mean responses for each treatment. Now we need to extract the 95% confidence intervals from the ANOVA result using the confint() function."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
